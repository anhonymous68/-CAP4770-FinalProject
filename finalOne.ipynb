{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import hashlib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/users/hoang/Desktop/Study/CAP4770/Project/USVideos/USVideos.csv'\n",
    "#                  names = ['video_id', 'trending_date', 'title', 'channel_title','category_id','publish_time',\n",
    "# 'tags',\n",
    "# 'views',\n",
    "# 'likes',\n",
    "# 'dislikes',\n",
    "# 'comment_count',\n",
    "# 'thumbnail_link',\n",
    "# 'comments_disabled',\n",
    "# 'ratings_disabled',\n",
    "# 'video_error_or_removed',\n",
    "# 'description']\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[(df['title'] != '[none]' ) & (df['tags'] != '[none]' ) \\\n",
    "          & (df['views'] != '[none]' )& (df['likes'] != '[none]' ) \\\n",
    "          &(df['dislikes'] != '[none]' ) \\\n",
    "          &(df['comment_count'] != '[none]' )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = data.drop(['description', 'thumbnail_link', 'comments_disabled', 'ratings_disabled', 'video_error_or_removed', 'publish_time', 'channel_title', 'trending_date', 'video_id', 'tags', 'title'], axis=1)\n",
    "preprocessed_data.head()\n",
    "text_data = data.drop(['views', 'likes', 'dislikes', 'comment_count', 'thumbnail_link', 'comments_disabled', 'ratings_disabled', 'video_error_or_removed','video_id', 'publish_time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessed_data.drop('category_id', axis=1)\n",
    "y = preprocessed_data['category_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize \n",
    "   \n",
    "ps = PorterStemmer() \n",
    "def getWords(col:str, data_notNull):\n",
    "    common_words = set(stopwords.words('english'))\n",
    "    tagsArray = text_data[col]\n",
    "    tag2D = []\n",
    "    tagsArray\n",
    "    \n",
    "    for (i,tag) in enumerate(tagsArray):\n",
    "        lineArray = tag.split('|')\n",
    "        words = []\n",
    "        for sentence in lineArray:\n",
    "            words = words + re.split(r'\\W+', sentence.strip())\n",
    "           \n",
    "        tag2D.append(words)\n",
    "        \n",
    "    for i in range(len(tag2D)):\n",
    "        temp = [u for u in tag2D[i] if u.lower() not in common_words] \n",
    "        temp = \" \".join(ps.stem(str(x)) for x in temp)\n",
    "        tag2D[i] = temp\n",
    "                \n",
    "    return tag2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2d_words = getWords('title',text_data)\n",
    "orr2d_words = getWords('tags', text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['modified_title'] = arr2d_words\n",
    "X['modified_tags'] = orr2d_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(X['modified_title'])\n",
    "X['labeled_title'] = le.transform(X['modified_title'])\n",
    "oc = LabelEncoder()\n",
    "oc.fit(X['modified_tags'])\n",
    "X['labeled_tags'] = oc.transform(X['modified_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop('modified_title', axis=1)\n",
    "X = X.drop('modified_tags', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_scores(y_test, y_score, n_classes):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    return fpr, tpr, roc_auc\n",
    "\n",
    "def histogram_feature(feature):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.hist(data[feature])\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('No. of Videos')\n",
    "\n",
    "def histogram_log_feature(feature):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.hist(data[feature], log=True)\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Log(No. of Videos)')\n",
    "\n",
    "def bivariate_scatterplot(feature1, feature2):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.scatter(x=data[feature1], y=data[feature2], edgecolor=\"#000000\", linewidths=0.5)\n",
    "    ax.set(xlabel=feature1, ylabel=feature2)\n",
    "\n",
    "def kdeplot(feature, data):\n",
    "    sns.kdeplot(data[feature], shade=true)\n",
    "\n",
    "def countplot(feature, data):\n",
    "    sns.countplot(x=feature, data=data, linewidth=5)\n",
    "\n",
    "#generates an ROC curve for one feature\n",
    "#args are false positive and true positve rate array for one class\n",
    "#and the roc_auc for that class\n",
    "def single_attribute_roc_curve(fpr_arr, tpr_arr, roc_auc_arr):\n",
    "    \n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr_arr, tpr_arr, color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc_arr)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "def full_attr_roc_curve(fpr, tpr, roc_auc, y_test, y_score, n_classes):\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    #grabs all unique false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    #interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    lw = 2\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "             label='micro-average ROC curve (area = {0:0.2f})'\n",
    "                   ''.format(roc_auc[\"micro\"]),\n",
    "             color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "             label='macro-average ROC curve (area = {0:0.2f})'\n",
    "                   ''.format(roc_auc[\"macro\"]),\n",
    "             color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'tan', 'rosybrown', 'lightcoral', 'maroon', 'peru',\n",
    "                   'darkorange', 'gold', 'darkkhaki', 'lawngreen', 'turquoise', 'lightcyan', 'steelblue',\n",
    "                    'slategray','indigo', 'violet', 'salmon', 'dodgerblue', 'darkgoldenrod' , 'burlywood', 'lime',\n",
    "                   'yellow', 'bisque', 'forestgreen', 'aquamarine', 'indianred', 'mediumorchid', 'cadetblue', 'sandybrown',\n",
    "                   'peachpuff'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "                 label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                 ''.format(i, roc_auc[i]))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Multi class ROC curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./US_category_id.json\") as f:\n",
    "    categories = json.load(f)['items']\n",
    "    \n",
    "categories\n",
    "\n",
    "category_list = []\n",
    "category_map = {}\n",
    "for cat in categories:\n",
    "    category_id = int(cat['id'])\n",
    "    category_map[category_id] = cat['snippet']['title']\n",
    "\n",
    "for cat in categories:\n",
    "    category_id = int(cat['id'])\n",
    "    category_list.append(category_id)\n",
    "\n",
    "# y = label_binarize(y, classes=y.unique().tolist())\n",
    "# n_classes = y.shape[1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Ox_train, Ox_test, Oy_train, Oy_test = train_test_split(X,y, test_size=0.35)\n",
    "\n",
    "text_features_train = X_train.drop(['views', 'likes', 'dislikes', 'comment_count'], axis=1)\n",
    "text_features_test = X_test.drop(['views', 'likes', 'dislikes', 'comment_count'], axis=1)\n",
    "X_train = X_train.drop(['labeled_title', 'labeled_tags'], axis=1)\n",
    "X_test = X_test.drop(['labeled_title', 'labeled_tags'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index().drop('index', axis=1)\n",
    "X_test = X_test.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_scaler = QuantileTransformer(output_distribution='uniform').fit(X_train)\n",
    "quantile_transformer = QuantileTransformer(output_distribution='uniform').fit(X_train)\n",
    "Xq_train = quantile_scaler.transform(X_train)\n",
    "Xq_test = quantile_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xq_train = quantile_scaler.transform(X_train)\n",
    "Xq_test = quantile_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = text_features_train.reset_index().drop('index',axis=1).join(pd.DataFrame(Xq_train, columns=['views','likes','dislikes','comment_count']))\n",
    "payload_test = text_features_test.reset_index().drop('index',axis=1).join(pd.DataFrame(Xq_test, columns=['views','likes','dislikes','comment_count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'n_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-68ccad3674b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpayload\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'n_estimator'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "start_time = time.time()\n",
    "model = RandomForestClassifier(n_estimator = 100).fit(payload, y_train)\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(payload_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9063808194849676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8838253720197999"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (accuracy_score(y_test, predict))\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score(y_test, predict, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
